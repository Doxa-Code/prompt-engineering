# Mitigação de Alucinações com Prompting

Para reduzir o risco de **alucinações** (quando o modelo gera informações incorretas ou irreais), considere as seguintes abordagens:

- **🔍 Use instruções claras e específicas**: Ao ser preciso no que pede, o modelo tende a responder de forma mais confiável.
- **📚 Solicite fontes ou justificativas**: Peça ao modelo para fornecer fontes ou explicações que sustentem suas respostas.
- **🔗 Combine com RAG (Recuperação e Geração de Fatos)**: Ao integrar fontes externas de dados, você garante que a resposta se baseie em informações reais e verificáveis.

- **⚖️ Reduza a temperatura** e **🛠️ Aumente o controle** no prompt: Com menor temperatura e mais controle, as respostas tendem a ser mais factuais e coerentes.
